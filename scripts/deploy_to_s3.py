#!/usr/bin/env python3
"""
Deploy ChatGPT usage data to an S3 bucket with IP-based access restrictions.

This script uploads the HTML and data files generated by the ChatGPT data
analysis tools to an S3 bucket configured as a static website. It can also
set up the bucket with IP-based access restrictions to ensure the site is
only accessible from your corporate network.
"""

import argparse
import json
import logging
import os
import sys
from pathlib import Path
from typing import List, Optional, Tuple, Dict, Any

import boto3
from boto3.exceptions import S3UploadFailedError
from botocore.exceptions import ClientError, NoCredentialsError, ProfileNotFound

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(levelname)s - %(message)s",
)
logger = logging.getLogger("deploy_to_s3")


def setup_s3_bucket(
    bucket_name: str,
    region: str,
    corporate_ip_ranges: Optional[List[str]] = None,
    create_if_missing: bool = True,
    skip_website_config: bool = False,
) -> bool:
    """
    Set up an S3 bucket as a static website with optional IP restrictions.

    Args:
        bucket_name: Name of the S3 bucket
        region: AWS region for the bucket
        corporate_ip_ranges: List of CIDR blocks for corporate network access
        create_if_missing: Whether to create the bucket if it doesn't exist
        skip_website_config: Skip the website configuration step

    Returns:
        bool: True if setup was successful, False otherwise
    """
    s3_client = boto3.client("s3", region_name=region)

    # Check if bucket exists
    try:
        s3_client.head_bucket(Bucket=bucket_name)
        logger.info(f"Bucket {bucket_name} already exists")
    except ClientError as e:
        error_code = e.response.get("Error", {}).get("Code", "")
        if error_code == "404" and create_if_missing:
            logger.info(f"Creating bucket {bucket_name} in {region}")
            try:
                if region == "us-east-1":
                    s3_client.create_bucket(Bucket=bucket_name)
                else:
                    s3_client.create_bucket(
                        Bucket=bucket_name,
                        CreateBucketConfiguration={"LocationConstraint": region},
                    )
            except ClientError as create_error:
                logger.error(f"Failed to create bucket: {create_error}")
                return False
        else:
            logger.error(f"Error accessing bucket: {e}")
            return False

    # Enable website hosting if not skipped
    if not skip_website_config:
        try:
            s3_client.put_bucket_website(
                Bucket=bucket_name,
                WebsiteConfiguration={
                    "IndexDocument": {"Suffix": "index.html"},
                    "ErrorDocument": {"Key": "error.html"},
                },
            )
            logger.info(f"Enabled static website hosting for {bucket_name}")
        except ClientError as e:
            logger.error(f"Failed to configure website hosting: {e}")
            logger.warning("This might be due to bucket settings or insufficient permissions.")
            logger.warning("You can try using the --skip-website-config option to skip this step.")
            logger.warning("Files will still be uploaded but won't be configured as a website.")
            return False

    # Set bucket policy for IP restriction if specified
    if corporate_ip_ranges:
        try:
            bucket_policy = {
                "Version": "2012-10-17",
                "Statement": [
                    {
                        "Effect": "Deny",
                        "Principal": "*",
                        "Action": "s3:*",
                        "Resource": [
                            f"arn:aws:s3:::{bucket_name}",
                            f"arn:aws:s3:::{bucket_name}/*",
                        ],
                        "Condition": {
                            "NotIpAddress": {
                                "aws:SourceIp": corporate_ip_ranges
                            }
                        },
                    },
                    {
                        "Effect": "Allow",
                        "Principal": "*",
                        "Action": ["s3:GetObject", "s3:ListBucket"],
                        "Resource": [
                            f"arn:aws:s3:::{bucket_name}",
                            f"arn:aws:s3:::{bucket_name}/*",
                        ],
                    },
                ],
            }

            s3_client.put_bucket_policy(
                Bucket=bucket_name, Policy=json.dumps(bucket_policy)
            )
            logger.info(
                f"Set bucket policy to restrict access to IP ranges: {corporate_ip_ranges}"
            )
        except ClientError as e:
            logger.error(f"Failed to set bucket policy: {e}")
            logger.warning("This might be due to bucket settings or insufficient permissions.")
            return False

    return True


def setup_s3_bucket_with_session(
    bucket_name: str,
    region: str,
    corporate_ip_ranges: Optional[List[str]] = None,
    create_if_missing: bool = True,
    session: Optional[boto3.Session] = None,
    skip_website_config: bool = False,
) -> bool:
    """
    Set up an S3 bucket as a static website with optional IP restrictions using a specific boto3 session.

    Args:
        bucket_name: Name of the S3 bucket
        region: AWS region for the bucket
        corporate_ip_ranges: List of CIDR blocks for corporate network access
        create_if_missing: Whether to create the bucket if it doesn't exist
        session: Boto3 session to use
        skip_website_config: Skip the website configuration step

    Returns:
        bool: True if setup was successful, False otherwise
    """
    if session is None:
        session = boto3.Session(region_name=region)
    
    s3_client = session.client("s3")

    # Check if bucket exists
    try:
        s3_client.head_bucket(Bucket=bucket_name)
        logger.info(f"Bucket {bucket_name} already exists")
    except ClientError as e:
        error_code = e.response.get("Error", {}).get("Code", "")
        if error_code == "404" and create_if_missing:
            logger.info(f"Creating bucket {bucket_name} in {region}")
            try:
                if region == "us-east-1":
                    s3_client.create_bucket(Bucket=bucket_name)
                else:
                    s3_client.create_bucket(
                        Bucket=bucket_name,
                        CreateBucketConfiguration={"LocationConstraint": region},
                    )
            except ClientError as create_error:
                logger.error(f"Failed to create bucket: {create_error}")
                return False
        else:
            logger.error(f"Error accessing bucket: {e}")
            return False

    # Enable website hosting if not skipped
    if not skip_website_config:
        try:
            s3_client.put_bucket_website(
                Bucket=bucket_name,
                WebsiteConfiguration={
                    "IndexDocument": {"Suffix": "index.html"},
                    "ErrorDocument": {"Key": "error.html"},
                },
            )
            logger.info(f"Enabled static website hosting for {bucket_name}")
        except ClientError as e:
            logger.error(f"Failed to configure website hosting: {e}")
            logger.warning("This might be due to bucket settings or insufficient permissions.")
            logger.warning("You can try using the --skip-website-config option to skip this step.")
            logger.warning("Files will still be uploaded but won't be configured as a website.")
            return False

    # Set bucket policy for IP restriction if specified
    if corporate_ip_ranges:
        try:
            bucket_policy = {
                "Version": "2012-10-17",
                "Statement": [
                    {
                        "Effect": "Deny",
                        "Principal": "*",
                        "Action": "s3:*",
                        "Resource": [
                            f"arn:aws:s3:::{bucket_name}",
                            f"arn:aws:s3:::{bucket_name}/*",
                        ],
                        "Condition": {
                            "NotIpAddress": {
                                "aws:SourceIp": corporate_ip_ranges
                            }
                        },
                    },
                    {
                        "Effect": "Allow",
                        "Principal": "*",
                        "Action": ["s3:GetObject", "s3:ListBucket"],
                        "Resource": [
                            f"arn:aws:s3:::{bucket_name}",
                            f"arn:aws:s3:::{bucket_name}/*",
                        ],
                    },
                ],
            }

            s3_client.put_bucket_policy(
                Bucket=bucket_name, Policy=json.dumps(bucket_policy)
            )
            logger.info(
                f"Set bucket policy to restrict access to IP ranges: {corporate_ip_ranges}"
            )
        except ClientError as e:
            logger.error(f"Failed to set bucket policy: {e}")
            logger.warning("This might be due to bucket settings or insufficient permissions.")
            return False

    return True


def get_content_type(file_path: str) -> str:
    """
    Determine the appropriate content type based on file extension.

    Args:
        file_path: Path to the file

    Returns:
        str: Content type for the file
    """
    extension = os.path.splitext(file_path)[1].lower()
    content_types = {
        ".html": "text/html",
        ".htm": "text/html",
        ".css": "text/css",
        ".js": "application/javascript",
        ".json": "application/json",
        ".png": "image/png",
        ".jpg": "image/jpeg",
        ".jpeg": "image/jpeg",
        ".gif": "image/gif",
        ".svg": "image/svg+xml",
        ".csv": "text/csv",
        ".txt": "text/plain",
        ".pdf": "application/pdf",
    }
    return content_types.get(extension, "application/octet-stream")


def upload_file(
    s3_client: Any, local_path: str, bucket_name: str, s3_path: str
) -> bool:
    """
    Upload a single file to S3 with appropriate content type.

    Args:
        s3_client: Boto3 S3 client
        local_path: Path to local file
        bucket_name: Name of the S3 bucket
        s3_path: Path within the S3 bucket

    Returns:
        bool: True if upload was successful, False otherwise
    """
    try:
        content_type = get_content_type(local_path)
        s3_client.upload_file(
            local_path,
            bucket_name,
            s3_path,
            ExtraArgs={"ContentType": content_type},
        )
        return True
    except (ClientError, S3UploadFailedError) as e:
        logger.error(f"Failed to upload {local_path}: {e}")
        return False


def create_error_page(bucket_name: str, s3_client: Any) -> bool:
    """
    Create and upload a simple error page for the S3 website.

    Args:
        bucket_name: Name of the S3 bucket
        s3_client: Boto3 S3 client

    Returns:
        bool: True if successful, False otherwise
    """
    error_html = """<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Error - ChatGPT Usage Data</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 20px;
            color: #333;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f8f9fa;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        h1 {
            color: #d9534f;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Error</h1>
        <p>The requested page was not found or you don't have permission to access it.</p>
        <p>Please check the URL or contact your administrator for assistance.</p>
    </div>
</body>
</html>
"""
    try:
        # Create a temporary error.html file
        with open("error.html", "w") as f:
            f.write(error_html)

        # Upload to S3
        s3_client.upload_file(
            "error.html",
            bucket_name,
            "error.html",
            ExtraArgs={"ContentType": "text/html"},
        )

        # Clean up
        os.remove("error.html")
        return True
    except Exception as e:
        logger.error(f"Failed to create error page: {e}")
        if os.path.exists("error.html"):
            os.remove("error.html")
        return False


def deploy_to_s3(
    bucket_name: str,
    html_file: str,
    data_dir: str,
    region: str = "us-east-1",
    corporate_ip_ranges: Optional[List[str]] = None,
    profile: Optional[str] = None,
    skip_website_config: bool = False,
) -> bool:
    """
    Deploy HTML and data files to an S3 bucket configured as a static website.

    Args:
        bucket_name: Name of the S3 bucket
        html_file: Path to the HTML file to upload
        data_dir: Directory containing data files to upload
        region: AWS region for the bucket
        corporate_ip_ranges: List of CIDR blocks for corporate network access
        profile: AWS profile to use
        skip_website_config: Skip the website configuration step

    Returns:
        bool: True if deployment was successful, False otherwise
    """
    try:
        # Initialize boto3 session with profile if specified
        if profile:
            logger.info(f"Using AWS profile: {profile}")
            session = boto3.Session(profile_name=profile, region_name=region)
            s3_client = session.client("s3")
            # Also create a new client for the setup_s3_bucket function
            region = session.region_name
        else:
            session = boto3.Session(region_name=region)
            s3_client = session.client("s3")

        # Set up the bucket (pass the session if profile was specified)
        if profile:
            if not setup_s3_bucket_with_session(bucket_name, region, corporate_ip_ranges, session=session, skip_website_config=skip_website_config):
                return False
        else:
            if not setup_s3_bucket(bucket_name, region, corporate_ip_ranges, skip_website_config=skip_website_config):
                return False

        # Create and upload error page
        if not create_error_page(bucket_name, s3_client):
            logger.warning("Failed to create error page, continuing with deployment")

        # Upload HTML file
        html_path = Path(html_file)
        if not html_path.exists():
            logger.error(f"HTML file not found: {html_file}")
            return False

        logger.info(f"Uploading {html_path.name}")
        if not upload_file(s3_client, str(html_path), bucket_name, html_path.name):
            return False

        # Upload data files
        data_path = Path(data_dir)
        if not data_path.exists() or not data_path.is_dir():
            logger.error(f"Data directory not found: {data_dir}")
            return False

        file_count = 0
        for root, _, files in os.walk(data_dir):
            for file in files:
                local_path = os.path.join(root, file)
                # Calculate relative path for S3
                rel_path = os.path.relpath(local_path, os.path.dirname(data_dir))
                
                logger.info(f"Uploading {rel_path}")
                if upload_file(s3_client, local_path, bucket_name, rel_path):
                    file_count += 1

        logger.info(f"Successfully uploaded {file_count} files")
        
        if skip_website_config:
            logger.info(f"Files uploaded to S3 bucket: {bucket_name}")
            logger.info(f"Since website hosting was skipped, you'll need to access the files directly via S3 URLs")
            logger.info(f"Example URL: https://{bucket_name}.s3.{region}.amazonaws.com/index.html")
        else:
            website_url = f"http://{bucket_name}.s3-website-{region}.amazonaws.com"
            logger.info(f"Website deployed to: {website_url}")
        
        if corporate_ip_ranges:
            logger.info(f"Note: Website is only accessible from IP ranges: {corporate_ip_ranges}")
        
        return True

    except NoCredentialsError:
        logger.error("AWS credentials not found. Please configure your AWS credentials.")
        logger.info("If using AWS SSO, make sure to run 'aws sso login --profile YOUR_PROFILE' first.")
        return False
    except ProfileNotFound:
        logger.error(f"AWS profile '{profile}' not found.")
        logger.info("Check your ~/.aws/config file to ensure the profile exists.")
        return False
    except Exception as e:
        logger.error(f"Deployment failed: {e}")
        return False


def parse_ip_ranges(ip_ranges_str: str) -> List[str]:
    """
    Parse comma-separated IP ranges string into a list.

    Args:
        ip_ranges_str: Comma-separated string of IP CIDR ranges

    Returns:
        List[str]: List of IP CIDR ranges
    """
    if not ip_ranges_str:
        return []
    return [ip_range.strip() for ip_range in ip_ranges_str.split(",")]


def main() -> int:
    """Main entry point for the script."""
    parser = argparse.ArgumentParser(
        description="Deploy ChatGPT usage data to an S3 bucket"
    )
    parser.add_argument(
        "--bucket-name",
        required=True,
        help="Name of the S3 bucket to deploy to",
    )
    parser.add_argument(
        "--html-file",
        default="index.html",
        help="Path to the HTML file to upload (default: index.html)",
    )
    parser.add_argument(
        "--data-dir",
        default="./data",
        help="Directory containing data files to upload (default: ./data)",
    )
    parser.add_argument(
        "--region",
        default="us-east-1",
        help="AWS region for the S3 bucket (default: us-east-1)",
    )
    parser.add_argument(
        "--corporate-ip-ranges",
        help="Comma-separated list of corporate IP CIDR ranges for access restriction",
    )
    parser.add_argument(
        "--profile",
        help="AWS profile to use for credentials",
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Enable verbose logging",
    )
    parser.add_argument(
        "--skip-website-config",
        action="store_true",
        help="Skip configuring the bucket as a website (use for buckets that don't support website hosting)",
    )

    args = parser.parse_args()

    # Set log level
    if args.verbose:
        logger.setLevel(logging.DEBUG)

    # Parse IP ranges
    ip_ranges = parse_ip_ranges(args.corporate_ip_ranges) if args.corporate_ip_ranges else None

    # Deploy to S3
    success = deploy_to_s3(
        bucket_name=args.bucket_name,
        html_file=args.html_file,
        data_dir=args.data_dir,
        region=args.region,
        corporate_ip_ranges=ip_ranges,
        profile=args.profile,
        skip_website_config=args.skip_website_config,
    )

    return 0 if success else 1


if __name__ == "__main__":
    sys.exit(main())
